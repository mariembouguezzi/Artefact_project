{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction \n\nThis project is inspired from the competition entitled **Microsoft Rice Disease Classification Challenge** on **Zindi** plateform :\n\nhttps://zindi.africa/competitions/microsoft-rice-disease-classification-challenge\n\n\nDataset source : https://zindi.africa/competitions/microsoft-rice-disease-classification-challenge/data \n\n\nThe architecture of the following developed model is inspired from the following article\n\n                       **Image Classification Transfer Learning and Fine Tuning using TensorFlow**\n                       \nhttps://towardsdatascience.com/image-classification-transfer-learning-and-fine-tuning-using-tensorflow-a791baf9dbf3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Overall, in terms of technology stack for our deepl learning model building, we use :\n\n      Tensorflow, \n      TF dataset, \n      CNN(Convolutional Neural Networks), \n      data augmentation, \n      learning transfer,\n      pretrained model : EfficientNetB0,\n      Fine tuning.           ","metadata":{}},{"cell_type":"markdown","source":"**Transfer learning : définition**  (https://datascientest.com/transfer-learning )\n\nCommençons d’abord par définir ce terme de plus en plus utilisé en Data Science.\n\nLe Transfer Learning, ou apprentissage par transfert en français, désigne l’ensemble des méthodes qui permettent de transférer les connaissances acquises à partir de la résolution de problèmes donnés pour traiter un autre problème. \n\nLe Transfer Learning a connu un grand succès avec l’essor du Deep Learning.  En effet, bien souvent, les modèles utilisés dans ce domaine nécessitent des temps de calcul élevés et des ressources importantes. Or, en utilisant des modèles pré-entraînés comme point de départ, le Transfer Learning permet de développer rapidement des modèles performants et résoudre efficacement des problèmes complexes en Computer Vision ou Natural Language Processing, NLP.","metadata":{}},{"cell_type":"markdown","source":"**Transfer learning vs Fine tuning** : https://www.youtube.com/watch?v=3nbin3bT8ec & https://www.youtube.com/watch?v=h_rz7_sIV40 (very interesting course) ","metadata":{}},{"cell_type":"markdown","source":"Weights & Biases est un outil qui permet de suivre et facilement enregistrer les performances de modèles deep learning. \n(https://machine-learning.paperspace.com/wiki/weights-and-biases)\n(https://www.youtube.com/watch?v=EeqhOSvNX-A)\n\nhttps://siecledigital.fr/2019/12/20/weights-biases-loutil-pour-suivre-les-performances-de-vos-modeles-de-deep-learning/\nhttps://siecledigital.fr/2019/01/30/differences-intelligence-artificielle-machine-learning-deep-learning/\n","metadata":{}},{"cell_type":"markdown","source":"## Import all the Dependencies","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport shutil\nfrom pathlib import Path\nfrom glob import glob\nimport os\nimport warnings\nimport torch\n\nfrom tensorflow.keras import models, layers\nfrom tensorflow import expand_dims\nfrom PIL import Image\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\n\nfrom keras.models import load_model\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:35:47.406085Z","iopub.execute_input":"2022-09-06T04:35:47.406660Z","iopub.status.idle":"2022-09-06T04:35:55.219194Z","shell.execute_reply.started":"2022-09-06T04:35:47.406571Z","shell.execute_reply":"2022-09-06T04:35:55.218217Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n    except RuntimeError as e:\n            print(e)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:35:55.221311Z","iopub.execute_input":"2022-09-06T04:35:55.221943Z","iopub.status.idle":"2022-09-06T04:35:55.296453Z","shell.execute_reply.started":"2022-09-06T04:35:55.221905Z","shell.execute_reply":"2022-09-06T04:35:55.295306Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Data collection & pre-processing step (using Tensorflow dataset)","metadata":{}},{"cell_type":"code","source":"train_data_csv = pd.read_csv('../input/rgb-csv/RGB_train_data.csv')\ntrain_data_csv","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:35:55.297990Z","iopub.execute_input":"2022-09-06T04:35:55.298615Z","iopub.status.idle":"2022-09-06T04:35:55.347567Z","shell.execute_reply.started":"2022-09-06T04:35:55.298576Z","shell.execute_reply":"2022-09-06T04:35:55.346713Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Set all the Constants","metadata":{}},{"cell_type":"code","source":"batch_size_inst = 5\nimage_size_inst = (224,224)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:35:55.350893Z","iopub.execute_input":"2022-09-06T04:35:55.351166Z","iopub.status.idle":"2022-09-06T04:35:55.355609Z","shell.execute_reply.started":"2022-09-06T04:35:55.351141Z","shell.execute_reply":"2022-09-06T04:35:55.354347Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Import data into tensorflow dataset object","metadata":{}},{"cell_type":"markdown","source":"We will use image_dataset_from_directory api to load all images in tensorflow dataset: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory","metadata":{}},{"cell_type":"code","source":"# Train images path\npath = '../input/rgb-images/RGB_images'\ndataset = tf.keras.preprocessing.image_dataset_from_directory(\n    path,\n    shuffle = True,\n    batch_size = batch_size_inst,\n    image_size = image_size_inst,\n    follow_links=False\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:35:55.357519Z","iopub.execute_input":"2022-09-06T04:35:55.357901Z","iopub.status.idle":"2022-09-06T04:36:03.072317Z","shell.execute_reply.started":"2022-09-06T04:35:55.357835Z","shell.execute_reply":"2022-09-06T04:36:03.071429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_classes = dataset.class_names\ntrain_classes","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:03.076693Z","iopub.execute_input":"2022-09-06T04:36:03.078956Z","iopub.status.idle":"2022-09-06T04:36:03.087505Z","shell.execute_reply.started":"2022-09-06T04:36:03.078872Z","shell.execute_reply":"2022-09-06T04:36:03.086649Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:03.089164Z","iopub.execute_input":"2022-09-06T04:36:03.089845Z","iopub.status.idle":"2022-09-06T04:36:03.104807Z","shell.execute_reply.started":"2022-09-06T04:36:03.089810Z","shell.execute_reply":"2022-09-06T04:36:03.103845Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:03.106412Z","iopub.execute_input":"2022-09-06T04:36:03.107149Z","iopub.status.idle":"2022-09-06T04:36:03.422815Z","shell.execute_reply.started":"2022-09-06T04:36:03.107100Z","shell.execute_reply":"2022-09-06T04:36:03.421721Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"As you can see above, each element in the dataset is a tuple. First element is a batch of 5 elements of images. Second element is a batch of 32 elements of class labels","metadata":{}},{"cell_type":"markdown","source":"### Visualize some of the images from our dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor image_batch , label_batch in dataset.take(2):\n    for i in range(5):\n        ax= plt.subplot(2,3,i+1)\n        plt.imshow(image_batch[i].numpy().astype('uint8'))\n        plt.title(train_classes[label_batch[i]])\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:03.424334Z","iopub.execute_input":"2022-09-06T04:36:03.424718Z","iopub.status.idle":"2022-09-06T04:36:04.243869Z","shell.execute_reply.started":"2022-09-06T04:36:03.424676Z","shell.execute_reply":"2022-09-06T04:36:04.242704Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Since neural networks work best with float32 or float16 datatypes, we need to convert the uint8 datatype of the images to float32 datatype.","metadata":{}},{"cell_type":"code","source":"def data_type_images(image, label):\n    image = tf.cast(image, dtype = tf.float32)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.247628Z","iopub.execute_input":"2022-09-06T04:36:04.249343Z","iopub.status.idle":"2022-09-06T04:36:04.255175Z","shell.execute_reply.started":"2022-09-06T04:36:04.249293Z","shell.execute_reply":"2022-09-06T04:36:04.253551Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset.element_spec","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.256915Z","iopub.execute_input":"2022-09-06T04:36:04.257731Z","iopub.status.idle":"2022-09-06T04:36:04.266091Z","shell.execute_reply.started":"2022-09-06T04:36:04.257694Z","shell.execute_reply":"2022-09-06T04:36:04.264860Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Great! Now all the images are of size (224, 224, 3) and the datatypes are of the float32 datatype. The None shape indicates that the images and labels have been split into batches which we specified earlier.\n\nOh and another thing we could do to increase our processing speed and thereby decrease the time taken to train a neural network in the process is by implementing the mixed_precision training from the keras module. Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory. The Keras mixed precision API allows us to use a mix of float16 with float32, to get the performance benefits from float16 and the numeric stability benefits from float32.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.267541Z","iopub.execute_input":"2022-09-06T04:36:04.268228Z","iopub.status.idle":"2022-09-06T04:36:04.278770Z","shell.execute_reply.started":"2022-09-06T04:36:04.268195Z","shell.execute_reply":"2022-09-06T04:36:04.277742Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Function to Split Dataset","metadata":{}},{"cell_type":"markdown","source":"Dataset should be bifurcated into 3 subsets, namely:\n\n    1) Training: Dataset to be used while training\n    2) Validation: Dataset to be tested against while training\n    3) Test: Dataset to be tested against after we trained a model","metadata":{}},{"cell_type":"code","source":"def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=1000):\n    \n    assert (train_split + test_split + val_split) == 1\n    \n    ds_size = len(ds)\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n        \n    train_size = int(train_split * ds_size)\n    \n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)\n    \n    val_ds = ds.skip(train_size).take(val_size)\n    \n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.280424Z","iopub.execute_input":"2022-09-06T04:36:04.281190Z","iopub.status.idle":"2022-09-06T04:36:04.289501Z","shell.execute_reply.started":"2022-09-06T04:36:04.281155Z","shell.execute_reply":"2022-09-06T04:36:04.288326Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.291014Z","iopub.execute_input":"2022-09-06T04:36:04.291865Z","iopub.status.idle":"2022-09-06T04:36:04.309238Z","shell.execute_reply.started":"2022-09-06T04:36:04.291822Z","shell.execute_reply":"2022-09-06T04:36:04.308088Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.map(data_type_images)\nval_ds = val_ds.map(data_type_images)\ntest_ds = test_ds.map(data_type_images)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.310861Z","iopub.execute_input":"2022-09-06T04:36:04.311500Z","iopub.status.idle":"2022-09-06T04:36:04.364939Z","shell.execute_reply.started":"2022-09-06T04:36:04.311465Z","shell.execute_reply":"2022-09-06T04:36:04.363970Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(train_ds)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.366391Z","iopub.execute_input":"2022-09-06T04:36:04.366740Z","iopub.status.idle":"2022-09-06T04:36:04.373790Z","shell.execute_reply.started":"2022-09-06T04:36:04.366706Z","shell.execute_reply":"2022-09-06T04:36:04.372699Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.375610Z","iopub.execute_input":"2022-09-06T04:36:04.376252Z","iopub.status.idle":"2022-09-06T04:36:04.386325Z","shell.execute_reply.started":"2022-09-06T04:36:04.376216Z","shell.execute_reply":"2022-09-06T04:36:04.385375Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"len(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.387481Z","iopub.execute_input":"2022-09-06T04:36:04.387787Z","iopub.status.idle":"2022-09-06T04:36:04.396297Z","shell.execute_reply.started":"2022-09-06T04:36:04.387761Z","shell.execute_reply":"2022-09-06T04:36:04.395101Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Cache, Shuffle, and Prefetch the Dataset","metadata":{}},{"cell_type":"code","source":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.397953Z","iopub.execute_input":"2022-09-06T04:36:04.398633Z","iopub.status.idle":"2022-09-06T04:36:04.408883Z","shell.execute_reply.started":"2022-09-06T04:36:04.398598Z","shell.execute_reply":"2022-09-06T04:36:04.407877Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"Data Augmentation is needed when we have less data, this boosts the accuracy of our model by augmenting the data and avoid overfitting.","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n    layers.experimental.preprocessing.RandomContrast(0.2),  \n    layers.experimental.preprocessing.RandomZoom(0.8),      \n])","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.410531Z","iopub.execute_input":"2022-09-06T04:36:04.410956Z","iopub.status.idle":"2022-09-06T04:36:04.443697Z","shell.execute_reply.started":"2022-09-06T04:36:04.410921Z","shell.execute_reply":"2022-09-06T04:36:04.442842Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture","metadata":{}},{"cell_type":"markdown","source":"Before we start with the actual transfer learning and fine-tuning, we will create a ModelCheckpoint callback which will create a checkpoint of our model which we can later revert back to, if needed. Here we save only the weights of the model and not the whole model itself as it can take some time. The validation accuracy is the metric being monitored here and we also set the save_best_only parameter to True and so the callback will only the save the weights of the model which has led to the highest validation accuracy.","metadata":{}},{"cell_type":"code","source":"def model_checkpoint(directory, name):\n    log_dir = directory + \"/\" + name\n    m_c = tf.keras.callbacks.ModelCheckpoint(filepath=log_dir,\n                                             monitor=\"val_accuracy\",\n                                             save_best_only=True,\n                                             save_weights_only=True,\n                                             mode= 'max',\n                                             verbose=2)\n    return m_c","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.445309Z","iopub.execute_input":"2022-09-06T04:36:04.445622Z","iopub.status.idle":"2022-09-06T04:36:04.450988Z","shell.execute_reply.started":"2022-09-06T04:36:04.445589Z","shell.execute_reply":"2022-09-06T04:36:04.449765Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"One regularization technique as augmentation data is Early-Stopping callback techniques. It can be used to reduce over-fitting and maybe improve our model’s accuracy scores on unseen test data. ","metadata":{}},{"cell_type":"code","source":"earlystop = EarlyStopping(\nmonitor='val_accuracy',\nmin_delta = 0.001,\npatience = 10,\nverbose = 2,\nmode = 'auto')","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.452599Z","iopub.execute_input":"2022-09-06T04:36:04.453351Z","iopub.status.idle":"2022-09-06T04:36:04.460508Z","shell.execute_reply.started":"2022-09-06T04:36:04.453308Z","shell.execute_reply":"2022-09-06T04:36:04.459471Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Okay now that we have preprocessed our data, visualized and created some handy callbacks, we move on the the acutal transfer learning part! We create the base model with **tf.keras.applications.efficientnet** and choose **EfficientNetB0** from the list of available EfficientNet prebuilt models. We also set the **include_top** parameter to **False** as we will be using our own output classifier layer suited to rice disease classification application. Since we are just **feature extracting** and **not fine-tuning** at this point, we will set **base_model.trainable = False.**","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:04.462323Z","iopub.execute_input":"2022-09-06T04:36:04.462746Z","iopub.status.idle":"2022-09-06T04:36:06.503508Z","shell.execute_reply.started":"2022-09-06T04:36:04.462711Z","shell.execute_reply":"2022-09-06T04:36:06.502611Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Now that we have our feature extraction base model ready, we will use the Keras Functional API to create our model which include the base model as functional layer for our feature extraction training model. The input layer is first created with the shape set to (224, 224, 3). The base model layer is then instantiated by passing the input layer while also setting the training parameter to False as we are not into fine-tuning the model yet. \n\nNext, the GlobalAveragePooling2D layer is set up to perform the pooling operation for our convolutional neural network. After that, a small change is done where this model differs from the conventional CNN, where the output layer is split separately into the Dense and Activation layers. Usually for any classification, the softmax activation can be included along with the output Dense layer. But here, since we have implemented mixed_precision training, we pass the Activation layer separately at the end as we want the output from the softmax activation to be of the float32 datatype which will rid us of any stability errors by maintaining numeric stability. Finally, the model is created by using the Model() function.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ninputs = layers.Input(shape = (224,224,3), name='inputLayer')\nx = data_augmentation(inputs)\nx = base_model(x, training = False)\nx = layers.GlobalAveragePooling2D(name='poolingLayer', keepdims= False)(x)\nx = layers.Dense(3, name='outputLayer')(x)\noutputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x)\n\nmodel = tf.keras.Model(inputs, outputs, name = \"FeatureExtractionModel\")","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:06.505088Z","iopub.execute_input":"2022-09-06T04:36:06.505720Z","iopub.status.idle":"2022-09-06T04:36:07.629835Z","shell.execute_reply.started":"2022-09-06T04:36:06.505681Z","shell.execute_reply":"2022-09-06T04:36:07.628826Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Now that we have built the model with just feature extraction included, we use the summary() method to get a look at the architecture of our feature extraction model:","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:07.631496Z","iopub.execute_input":"2022-09-06T04:36:07.631866Z","iopub.status.idle":"2022-09-06T04:36:07.649014Z","shell.execute_reply.started":"2022-09-06T04:36:07.631827Z","shell.execute_reply":"2022-09-06T04:36:07.648079Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"We see that the whole base model (EfficientNetB0) is implemented as a single functional layer in our feature extraction model. We also see the other layers created for building our model. The base model contains about 4 million parameters but they are all non-trainable since we have frozen the base model as we are not fine tuning but rather only extracting the features from the base model. The only trainable parameters come from the output Dense layer.\n\nNext, we get a detailed look at the various layers in our feature extraction model, their names, see if they are trainable or not, their data types and their corresponding data type policies.","metadata":{}},{"cell_type":"code","source":"for lnum, layer in enumerate(model.layers):\n    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:07.650456Z","iopub.execute_input":"2022-09-06T04:36:07.650868Z","iopub.status.idle":"2022-09-06T04:36:07.657975Z","shell.execute_reply.started":"2022-09-06T04:36:07.650828Z","shell.execute_reply":"2022-09-06T04:36:07.656697Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"0 inputLayer True float32 <Policy \"float32\">\n\n1 sequential True float32 <Policy \"mixed_float16\">\n\n2 efficientnetb0 False float32 <Policy \"mixed_float16\">\n\n3 poolingLayer True float32 <Policy \"mixed_float16\">\n\n4 outputLayer True float32 <Policy \"mixed_float16\">\n\n5 activationLayer True float32 <Policy \"float32\">","metadata":{}},{"cell_type":"markdown","source":"We can see that all the layers excepting the base model layer are trainable. The datatype policies indicate that apart from the input layer and the output activation layer which have float32 datatype policy, all the other layers are compatible with and employ the mixed_float16 datatype policy.\n\nNow we can move on to compiling and fitting our model. Since our labels are not one-hot encoded, we use the **SparseCategoricalCrossentropy()** loss function. We use the **Adam()** optimizer with its default learning rate and set the model metrics to measure accuracy.\n\nThen we begin to fit our feature extraction model. We save the model fitting history variable into hist_model and we train our model on the train dataset for 10 epochs. We use our test dataset as the validation data while training. We also pass the previously created callback function ModelCheckpoint which saves our model's best weights while monitoring the validation accuracy.","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:07.659446Z","iopub.execute_input":"2022-09-06T04:36:07.660191Z","iopub.status.idle":"2022-09-06T04:36:07.668143Z","shell.execute_reply.started":"2022-09-06T04:36:07.660145Z","shell.execute_reply":"2022-09-06T04:36:07.666909Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n              optimizer = tf.keras.optimizers.Adam(),\n              metrics = [\"accuracy\"])\n\nhist_model = model.fit(train_ds,\n                       epochs = 10,\n                       validation_data=val_ds,\n                       callbacks=[earlystop,model_checkpoint(\"Checkpoints\",\"model.ckpt\")])","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:36:07.673468Z","iopub.execute_input":"2022-09-06T04:36:07.673959Z","iopub.status.idle":"2022-09-06T04:37:58.189294Z","shell.execute_reply.started":"2022-09-06T04:36:07.673928Z","shell.execute_reply":"2022-09-06T04:37:58.187872Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Epoch 1/10\n2022-09-06 04:36:23.625739: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n427/427 [==============================] - 34s 27ms/step - loss: 0.8259 - accuracy: 0.6417 - val_loss: 0.7457 - val_accuracy: 0.6566\n\nEpoch 00001: val_accuracy improved from -inf to 0.65660, saving model to Checkpoints/model.ckpt\nEpoch 2/10\n427/427 [==============================] - 7s 17ms/step - loss: 0.7212 - accuracy: 0.7002 - val_loss: 0.6471 - val_accuracy: 0.7585\n\nEpoch 00002: val_accuracy improved from 0.65660 to 0.75849, saving model to Checkpoints/model.ckpt\nEpoch 3/10\n427/427 [==============================] - 7s 17ms/step - loss: 0.6677 - accuracy: 0.7274 - val_loss: 0.6288 - val_accuracy: 0.7660\n\nEpoch 00003: val_accuracy improved from 0.75849 to 0.76604, saving model to Checkpoints/model.ckpt\nEpoch 4/10\n427/427 [==============================] - 8s 19ms/step - loss: 0.6463 - accuracy: 0.7377 - val_loss: 0.7031 - val_accuracy: 0.7170\n\nEpoch 00004: val_accuracy did not improve from 0.76604\nEpoch 5/10\n427/427 [==============================] - 7s 17ms/step - loss: 0.6356 - accuracy: 0.7311 - val_loss: 0.6104 - val_accuracy: 0.7811\n\nEpoch 00005: val_accuracy improved from 0.76604 to 0.78113, saving model to Checkpoints/model.ckpt\nEpoch 6/10\n427/427 [==============================] - 7s 17ms/step - loss: 0.6168 - accuracy: 0.7513 - val_loss: 0.6141 - val_accuracy: 0.7585\n\nEpoch 00006: val_accuracy did not improve from 0.78113\nEpoch 7/10\n427/427 [==============================] - 7s 16ms/step - loss: 0.6228 - accuracy: 0.7504 - val_loss: 0.5796 - val_accuracy: 0.7849\n\nEpoch 00007: val_accuracy improved from 0.78113 to 0.78491, saving model to Checkpoints/model.ckpt\nEpoch 8/10\n427/427 [==============================] - 8s 18ms/step - loss: 0.6187 - accuracy: 0.7518 - val_loss: 0.5536 - val_accuracy: 0.7811\n\nEpoch 00008: val_accuracy did not improve from 0.78491\nEpoch 9/10\n427/427 [==============================] - 8s 18ms/step - loss: 0.5834 - accuracy: 0.7766 - val_loss: 0.5685 - val_accuracy: 0.7887\n\nEpoch 00009: val_accuracy improved from 0.78491 to 0.78868, saving model to Checkpoints/model.ckpt\nEpoch 10/10\n427/427 [==============================] - 7s 17ms/step - loss: 0.5716 - accuracy: 0.7738 - val_loss: 0.5622 - val_accuracy: 0.7774\n\nEpoch 00010: val_accuracy did not improve from 0.78868","metadata":{}},{"cell_type":"markdown","source":"We have also created a model checkpoint with the model weights leading to the highest validation accuracy incase we want to revert back to it after fine-tuning in the next stage. Let us evaluate our model on the whole test data now and store it in a variable.","metadata":{}},{"cell_type":"code","source":"model_results = model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:38:19.429556Z","iopub.execute_input":"2022-09-06T04:38:19.429907Z","iopub.status.idle":"2022-09-06T04:38:22.759079Z","shell.execute_reply.started":"2022-09-06T04:38:19.429876Z","shell.execute_reply":"2022-09-06T04:38:22.758174Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"54/54 [==============================] - 3s 12ms/step - loss: 0.5355 - accuracy: 0.7963","metadata":{}},{"cell_type":"markdown","source":"Not bad, not bad at all. 79.63% accuracy is pretty decent for just a feature extraction model.\n\nWe have got an accuracy of about 79.63% with our feature extraction model based on the EfficientNetB0 base model. How about we try to increase the accuracy score by fine-tuning our feature extraction model now. To do this, we set the layers of our model’s base_model (the EfficientNetB0 functional layer) to be trainable and unfreeze the previously frozen base model.","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:39:24.855762Z","iopub.execute_input":"2022-09-06T04:39:24.856364Z","iopub.status.idle":"2022-09-06T04:39:24.877548Z","shell.execute_reply.started":"2022-09-06T04:39:24.856317Z","shell.execute_reply":"2022-09-06T04:39:24.876670Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"However, The BatchNormalization layers need to be kept frozen. If they are also turned to trainable, the first epoch after unfreezing will significantly reduce accuracy. Since all the layers in the base model have been set to trainable, we use the following code block to again freeze only the BatchNormalization layers of our base model:","metadata":{}},{"cell_type":"code","source":"for layer in model.layers[1].layers:\n    if isinstance(layer, layers.BatchNormalization):\n        layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:40:26.241437Z","iopub.execute_input":"2022-09-06T04:40:26.241799Z","iopub.status.idle":"2022-09-06T04:40:26.247812Z","shell.execute_reply.started":"2022-09-06T04:40:26.241767Z","shell.execute_reply":"2022-09-06T04:40:26.246505Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"A quick check on the base model’s layers, their datatypes and policies and whether or not they’re trainable:","metadata":{}},{"cell_type":"code","source":"for lnum, layer in enumerate(model.layers[1].layers[-10:]):\n    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:43:14.832370Z","iopub.execute_input":"2022-09-06T04:43:14.832769Z","iopub.status.idle":"2022-09-06T04:43:14.839583Z","shell.execute_reply.started":"2022-09-06T04:43:14.832734Z","shell.execute_reply":"2022-09-06T04:43:14.838180Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"0 random_flip True float32 <Policy \"mixed_float16\">\n\n1 random_rotation True float32 <Policy \"mixed_float16\">\n\n2 random_contrast True float32 <Policy \"mixed_float16\">\n\n3 random_zoom True float32 <Policy \"mixed_float16\">","metadata":{}},{"cell_type":"markdown","source":"Good! Looks like all the layers in the base model are trainable and ready for fine tuning except for the BatchNormalization layers. I think we are good to proceed and fine tune our feature extraction model 'model'. We begin by compiling the model again since we have change the layer attributes (unfreeze), but this time, as a general good practice, we reduce the default learning rate of the Adam() optimizer by ten times so as to reduce overfitting and stop the model from learning/memorizing the train data to a great extent.\n\nThen we begin to fit our fine tuning model. We save the model fitting history variable into **hist_model_tuned** and we train our model on the train dataset for 20 epochs, however, we set the initial epoch to be the last epoch from our feature extraction model training which would be 10. Thus the fine tuning model training would start from epoch number 10 and would run upto 30 (20 epochs total). We again pass the previously created callback functions into the callbacks list : ModelCheckpoint which saves our model's best weights while monitoring the validation accuracy.","metadata":{}},{"cell_type":"code","source":"model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n              optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n              metrics = [\"accuracy\"])\nhist_model_tuned = model.fit(train_ds,\n                             epochs=30,\n                             validation_data=val_ds,\n                             initial_epoch=hist_model.epoch[-1],\n                             callbacks=[earlystop, model_checkpoint(\"Checkpoints\", \"model_tuned.ckpt\")])","metadata":{"execution":{"iopub.status.busy":"2022-09-06T04:48:32.204713Z","iopub.execute_input":"2022-09-06T04:48:32.205262Z","iopub.status.idle":"2022-09-06T05:01:10.328982Z","shell.execute_reply.started":"2022-09-06T04:48:32.205221Z","shell.execute_reply":"2022-09-06T05:01:10.328088Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Epoch 10/30\n427/427 [==============================] - 43s 69ms/step - loss: 0.6743 - accuracy: 0.7255 - val_loss: 0.6565 - val_accuracy: 0.7132\n\nEpoch 00010: val_accuracy improved from -inf to 0.71321, saving model to Checkpoints/model_tuned.ckpt\nEpoch 11/30\n427/427 [==============================] - 28s 66ms/step - loss: 0.5399 - accuracy: 0.7855 - val_loss: 0.3512 - val_accuracy: 0.8679\n\nEpoch 00011: val_accuracy improved from 0.71321 to 0.86792, saving model to Checkpoints/model_tuned.ckpt\nEpoch 12/30\n427/427 [==============================] - 28s 66ms/step - loss: 0.4539 - accuracy: 0.8262 - val_loss: 0.2976 - val_accuracy: 0.8717\n\nEpoch 00012: val_accuracy improved from 0.86792 to 0.87170, saving model to Checkpoints/model_tuned.ckpt\nEpoch 13/30\n427/427 [==============================] - 28s 66ms/step - loss: 0.3888 - accuracy: 0.8473 - val_loss: 0.2136 - val_accuracy: 0.9321\n\nEpoch 00013: val_accuracy improved from 0.87170 to 0.93208, saving model to Checkpoints/model_tuned.ckpt\nEpoch 14/30\n427/427 [==============================] - 28s 66ms/step - loss: 0.3683 - accuracy: 0.8618 - val_loss: 0.1768 - val_accuracy: 0.9509\n\nEpoch 00014: val_accuracy improved from 0.93208 to 0.95094, saving model to Checkpoints/model_tuned.ckpt\nEpoch 15/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.3067 - accuracy: 0.8890 - val_loss: 0.2299 - val_accuracy: 0.9170\n\nEpoch 00015: val_accuracy did not improve from 0.95094\nEpoch 16/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.2886 - accuracy: 0.8937 - val_loss: 0.1828 - val_accuracy: 0.9208\n\nEpoch 00016: val_accuracy did not improve from 0.95094\nEpoch 17/30\n427/427 [==============================] - 29s 67ms/step - loss: 0.2596 - accuracy: 0.8993 - val_loss: 0.1641 - val_accuracy: 0.9396\n\nEpoch 00017: val_accuracy did not improve from 0.95094\nEpoch 18/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.2419 - accuracy: 0.9077 - val_loss: 0.1125 - val_accuracy: 0.9698\n\nEpoch 00018: val_accuracy improved from 0.95094 to 0.96981, saving model to Checkpoints/model_tuned.ckpt\nEpoch 19/30\n427/427 [==============================] - 28s 67ms/step - loss: 0.2135 - accuracy: 0.9199 - val_loss: 0.1012 - val_accuracy: 0.9547\n\nEpoch 00019: val_accuracy did not improve from 0.96981\nEpoch 20/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1986 - accuracy: 0.9344 - val_loss: 0.1098 - val_accuracy: 0.9623\n\nEpoch 00020: val_accuracy did not improve from 0.96981\nEpoch 21/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1841 - accuracy: 0.9344 - val_loss: 0.0891 - val_accuracy: 0.9698\n\nEpoch 00021: val_accuracy did not improve from 0.96981\nEpoch 22/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1822 - accuracy: 0.9311 - val_loss: 0.1550 - val_accuracy: 0.9434\n\nEpoch 00022: val_accuracy did not improve from 0.96981\nEpoch 23/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1760 - accuracy: 0.9382 - val_loss: 0.1148 - val_accuracy: 0.9585\n\nEpoch 00023: val_accuracy did not improve from 0.96981\nEpoch 24/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1689 - accuracy: 0.9368 - val_loss: 0.0794 - val_accuracy: 0.9660\n\nEpoch 00024: val_accuracy did not improve from 0.96981\nEpoch 25/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1696 - accuracy: 0.9429 - val_loss: 0.0421 - val_accuracy: 0.9811\n\nEpoch 00025: val_accuracy improved from 0.96981 to 0.98113, saving model to Checkpoints/model_tuned.ckpt\nEpoch 26/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1276 - accuracy: 0.9532 - val_loss: 0.0523 - val_accuracy: 0.9774\n\nEpoch 00026: val_accuracy did not improve from 0.98113\nEpoch 27/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1479 - accuracy: 0.9443 - val_loss: 0.0794 - val_accuracy: 0.9774\n\nEpoch 00027: val_accuracy did not improve from 0.98113\nEpoch 28/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1464 - accuracy: 0.9433 - val_loss: 0.0928 - val_accuracy: 0.9736\n\nEpoch 00028: val_accuracy did not improve from 0.98113\nEpoch 29/30\n427/427 [==============================] - 28s 66ms/step - loss: 0.1422 - accuracy: 0.9457 - val_loss: 0.1327 - val_accuracy: 0.9509\n\nEpoch 00029: val_accuracy did not improve from 0.98113\nEpoch 30/30\n427/427 [==============================] - 28s 65ms/step - loss: 0.1404 - accuracy: 0.9475 - val_loss: 0.0960 - val_accuracy: 0.9623\n\nEpoch 00030: val_accuracy did not improve from 0.98113","metadata":{}},{"cell_type":"markdown","source":"Okay great! Looks like the validation accuracy has improved a lot. Let’s evaluate our fine-tuned model on the whole test data now and store it in a variable.","metadata":{}},{"cell_type":"code","source":"model_tuned_results = model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:01:25.002598Z","iopub.execute_input":"2022-09-06T05:01:25.002957Z","iopub.status.idle":"2022-09-06T05:01:25.679678Z","shell.execute_reply.started":"2022-09-06T05:01:25.002927Z","shell.execute_reply":"2022-09-06T05:01:25.678813Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"54/54 [==============================] - 1s 12ms/step - loss: 0.0694 - accuracy: 0.9778","metadata":{}},{"cell_type":"code","source":"model_tuned_results","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:04:59.230214Z","iopub.execute_input":"2022-09-06T05:04:59.230833Z","iopub.status.idle":"2022-09-06T05:04:59.237354Z","shell.execute_reply.started":"2022-09-06T05:04:59.230796Z","shell.execute_reply":"2022-09-06T05:04:59.236266Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"model_tuned_results is just a list containing loss and accuracy value : [0.06944755464792252, 0.9777777791023254]","metadata":{}},{"cell_type":"markdown","source":"Would you look at that! The fine-tuned model’s accuracy has improved and is now at about 97.78%. That is a huge increase we have achieved with just transfer learning and fine-tuning. Thanks EfficientNet for your model!","metadata":{}},{"cell_type":"markdown","source":"Since we have created two history objects for both the feature extraction model and the fine-tuned model, we can create a function to plot both the histories together and compare the training and the validation metrics to get a general idea of the performance of both models:","metadata":{}},{"cell_type":"code","source":"def compare_histories(original_history, new_history, initial_epochs):\n    \"\"\"\n    Compares two model history objects.\n    \"\"\"\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n    \n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"val_loss\"]\n\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n\n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n\n    plt.figure(figsize=(9, 9))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label='Training Accuracy')\n    plt.plot(total_val_acc, label='Validation Accuracy')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start of Fine Tuning')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label='Training Loss')\n    plt.plot(total_val_loss, label='Validation Loss')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start of Fine Tuning')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:01:30.379011Z","iopub.execute_input":"2022-09-06T05:01:30.379596Z","iopub.status.idle":"2022-09-06T05:01:30.391241Z","shell.execute_reply.started":"2022-09-06T05:01:30.379559Z","shell.execute_reply":"2022-09-06T05:01:30.390095Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Great! Now let us use both the hist_model and hist_model_tuned objects along the function with the initial_epochs set to 10 since we trained our first feature extraction model for 10 epochs.","metadata":{}},{"cell_type":"code","source":"compare_histories(hist_model, hist_model_tuned, initial_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:03:32.600118Z","iopub.execute_input":"2022-09-06T05:03:32.600711Z","iopub.status.idle":"2022-09-06T05:03:32.989899Z","shell.execute_reply.started":"2022-09-06T05:03:32.600675Z","shell.execute_reply":"2022-09-06T05:03:32.988974Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Now that we have trained our fine-tuned model based on EfficientNetB0, we will use it to make predictions on the whole test dataset and store it in preds:","metadata":{}},{"cell_type":"code","source":"preds = model.predict(test_ds, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:06:48.212479Z","iopub.execute_input":"2022-09-06T05:06:48.212856Z","iopub.status.idle":"2022-09-06T05:06:50.743055Z","shell.execute_reply.started":"2022-09-06T05:06:48.212823Z","shell.execute_reply":"2022-09-06T05:06:50.742153Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Note: The predictions are stored in a collection of prediction probabilities for each class for an individual test image.","metadata":{}},{"cell_type":"markdown","source":"Now that we have the prediction probabilities for each class for a given test image, we can easily obtain the prediction labels using the tf.argmax() function which returns the index which contains the highest probability along a given axis. We store the prediction labels in pred_labels:","metadata":{}},{"cell_type":"code","source":"pred_labels = tf.argmax(preds, axis=1)\npred_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:07:07.512403Z","iopub.execute_input":"2022-09-06T05:07:07.513386Z","iopub.status.idle":"2022-09-06T05:07:07.522946Z","shell.execute_reply.started":"2022-09-06T05:07:07.513345Z","shell.execute_reply":"2022-09-06T05:07:07.521695Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Now that we have made predictions and obtained the prediction labels, we can compare it with the test dataset labels to get detailed information on how well the fine-tuned model has made its predictions. We get the test labels from the test dataset using the following code block employing list comprehension:","metadata":{}},{"cell_type":"code","source":"test_labels = np.concatenate([y for x, y in test_ds], axis=0)\ntest_labels[:10]","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:24:13.760602Z","iopub.execute_input":"2022-09-06T05:24:13.761197Z","iopub.status.idle":"2022-09-06T05:24:13.807386Z","shell.execute_reply.started":"2022-09-06T05:24:13.761151Z","shell.execute_reply":"2022-09-06T05:24:13.806374Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Great! We now have both the predicted labels and the ground truth test labels. However to plot our prediction labels along with the associated image, we will need a dataset containing only the images extracted from test_data which contains both the images along with the labels. To do this, two steps are needed. First, we create an empty list and pass a for loop which extracts and appends each batch from the test dataset using the take() function to the newly created empty list test_image_batches. The -1 inside the take() function makes the for loop to pass through all the batches in the test data. The resulting output is a list of all the batches in the test data. Since the images are still in batches in the form of sublists inside the list test_image_batches, in step 2, we use list comprehension to extract each sublist, i.e each image from the main list and store them in the test_images list. \n\nThe resulting list test_images contains all the 270 (=54*5) test images contained in the original test dataset which is verified by using the len() funtion on the list.","metadata":{}},{"cell_type":"code","source":"# Step 1\ntest_image_batches = []\nfor images, labels in test_ds.take(-1):\n    test_image_batches.append(images.numpy())\n\n# Step 2\ntest_images = [item for sublist in test_image_batches for item in sublist]\nlen(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:24:24.068963Z","iopub.execute_input":"2022-09-06T05:24:24.070004Z","iopub.status.idle":"2022-09-06T05:24:24.229483Z","shell.execute_reply.started":"2022-09-06T05:24:24.069965Z","shell.execute_reply":"2022-09-06T05:24:24.228343Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Now that we have a list of test images(test_images), their ground truth test labels(test_labels) and their corresponding prediction labels(pred_labels) along with the prediction probabilities (preds), we can easily visualize the test images along with their predictions including the ground truth and prediction class names.\n\nHere, we take 9 random images from test_images and plot them along with the ground truth class names and predicted class names in the plot title, side by side using indexing on class_names with the corresponding ground truth and predicted labels. We also display the prediction probabilities of the predictions on each image to get an idea of how confident the model is in its predictions. Moreover, to make the plots looke good and more informative, for wrong predictions, we set the title color to red, whereas for correct predictions by our fine-tuning model, we set the title color to green.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,20))\nfor i in range(9):\n    random_int_index = random.choice(range(len(test_images)))\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_images[random_int_index]/255.)\n    if test_labels[random_int_index] == pred_labels[random_int_index]:\n        color = \"g\"\n    else:\n        color = \"r\"\n    plt.title(\"True Label: \" + train_classes[test_labels[random_int_index]] + \" || \" + \"Predicted Label: \" +\n              train_classes[pred_labels[random_int_index]] + \"\\n\" + \n              str(np.asarray(tf.reduce_max(preds, axis = 1))[random_int_index]), c=color)\n    plt.axis(False);","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:24:37.131652Z","iopub.execute_input":"2022-09-06T05:24:37.132050Z","iopub.status.idle":"2022-09-06T05:24:38.694751Z","shell.execute_reply.started":"2022-09-06T05:24:37.132000Z","shell.execute_reply":"2022-09-06T05:24:38.691109Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"As we have both the test and prediction labels, we can also use the classification_report() function from SciKit-Learn library and store the precision, recall and f1-scores for each class in a dictionary report by specifying the output_dict parameter to be True.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nreport = classification_report(test_labels, pred_labels, output_dict=True)\n\n#check a small slice of the dictionary\nimport itertools\ndict(itertools.islice(report.items(), 3))","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:51:33.536345Z","iopub.execute_input":"2022-09-06T05:51:33.536813Z","iopub.status.idle":"2022-09-06T05:51:34.039191Z","shell.execute_reply.started":"2022-09-06T05:51:33.536772Z","shell.execute_reply":"2022-09-06T05:51:34.038242Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"{'0': {'precision': 0.5483870967741935,\n  'recall': 0.551948051948052,\n  'f1-score': 0.5501618122977345,\n  'support': 154},\n  \n '1': {'precision': 0.24675324675324675,\n  'recall': 0.24050632911392406,\n  'f1-score': 0.24358974358974356,\n  'support': 79},\n  \n '2': {'precision': 0.10526315789473684,\n  'recall': 0.10810810810810811,\n  'f1-score': 0.10666666666666667,\n  'support': 37}}","metadata":{}},{"cell_type":"markdown","source":"Now that we have a dictionary containing the various evaluation metrics (precision, recall and f1-scores), how about we create a pandas dataframe which contains only the class names along with its corresponding F1-score. We choose the F1-score among the evaluation metrics as it achieves a balance between the precision and recall. You can read more about evaluation metrics here.\n\nHowever, in order to create that required dataframe, we will need to extract the class labels(keys) and the corresponding F1-score(part of values) from the classification report dictionary. This can be achieved by creating an empty dictionary f1scores and passing a for loop which goes through the original dictionary report's items(keys and values) and appends the class names using key-indexing and the corresponding F1-score by value-indexing.","metadata":{}},{"cell_type":"code","source":"f1scores = {}\nfor k,v in report.items():\n    if k == 'accuracy':\n        break\n    else:\n        f1scores[train_classes[int(k)]] = v['f1-score']\n        \n#check a small slice of the dictionary\ndict(itertools.islice(f1scores.items(), 5))","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:52:42.679168Z","iopub.execute_input":"2022-09-06T05:52:42.679801Z","iopub.status.idle":"2022-09-06T05:52:42.688305Z","shell.execute_reply.started":"2022-09-06T05:52:42.679761Z","shell.execute_reply":"2022-09-06T05:52:42.687098Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"{'blast__rice': 0.5501618122977345,\n 'brown__rice': 0.24358974358974356,\n 'healthy__rice': 0.10666666666666667}","metadata":{}},{"cell_type":"markdown","source":"Now that we have the required dictionary ready, we can easily create a dataframe F1 form the following line of code and sort the dataframe by the descending order of the various classes' F1-scores:","metadata":{}},{"cell_type":"code","source":"F1 = pd.DataFrame({\"Classes\":list(f1scores.keys()),\n                   \"F1-Scores\":list(f1scores.values())}).sort_values(\"F1-Scores\", ascending=False)\n\n#check a small slice of the dataframe\nF1","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:53:15.426493Z","iopub.execute_input":"2022-09-06T05:53:15.426862Z","iopub.status.idle":"2022-09-06T05:53:15.447242Z","shell.execute_reply.started":"2022-09-06T05:53:15.426830Z","shell.execute_reply":"2022-09-06T05:53:15.446081Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (6,4))\nplt.barh(F1[\"Classes\"], F1[\"F1-Scores\"])\nplt.ylim(-3,5)\nplt.xlim(0,0.7)\nplt.xlabel(\"F1-Scores\")\nplt.ylabel(\"Rice disease Classes\")\nplt.title(\"F1-Scores across various rice disease Classes\")\nplt.gca().invert_yaxis()\nfor i, v in enumerate(round(F1[\"F1-Scores\"],3)):\n    ax.text(v, i + .25, str(v), color='red');","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:54:36.203156Z","iopub.execute_input":"2022-09-06T05:54:36.203696Z","iopub.status.idle":"2022-09-06T05:54:36.433824Z","shell.execute_reply.started":"2022-09-06T05:54:36.203661Z","shell.execute_reply":"2022-09-06T05:54:36.432855Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"As a final evaluation step for our transfer learning fine-tuned model based on the EfficientNetB0 let’s visualize the most wrong predictions of our model, i.e the false(wrong) predictions of our model where the prediction probability is the highest. This will help us get an idea about our model as to whether it is getting confused on similar food classes or whether a test image has been wrongly labelled which would be a data input error.\n\nTo do this, let’ss create a neat dataframe Predictions which contains the 'Image Index' of the various images in the test dataset, their corresponding 'Test Labels', 'Test Classes', 'Prediction Labels', 'Prediction Classes', and 'Prediction Probability'.","metadata":{}},{"cell_type":"code","source":"Predictions = pd.DataFrame({\"Image Index\" : list(range(len(test_labels))), \n                            \"Test Labels\" : list(test_labels), \n                            \"Test Classes\" : [train_classes[i] for i in test_labels],\n                            \"Prediction Labels\" : list(np.asarray(pred_labels)),\n                            \"Prediction Classes\" : [train_classes[i] for i in pred_labels],\n                            \"Prediction Probability\" : [x for x in np.asarray(tf.reduce_max(preds, axis = 1))]})","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:55:19.599118Z","iopub.execute_input":"2022-09-06T05:55:19.599716Z","iopub.status.idle":"2022-09-06T05:55:19.701317Z","shell.execute_reply.started":"2022-09-06T05:55:19.599678Z","shell.execute_reply":"2022-09-06T05:55:19.699771Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"As we have created the required dataframe Predictions, we can also create a new column 'Correct Prediction' which contains True for test images that have been correctly predicted by our model and False for wrongly predicted test images:","metadata":{}},{"cell_type":"code","source":"Predictions[\"Correct Prediction\"] = Predictions[\"Test Labels\"] == Predictions[\"Prediction Labels\"]\nPredictions","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:55:28.092826Z","iopub.execute_input":"2022-09-06T05:55:28.093961Z","iopub.status.idle":"2022-09-06T05:55:28.119554Z","shell.execute_reply.started":"2022-09-06T05:55:28.093916Z","shell.execute_reply":"2022-09-06T05:55:28.118279Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"Great, our dataframe looks fantastic! However, this is not the final form of our dataframe. We want to subset our current dataframe with only those records where ‘Correct Prediction’ is equal to False as our aim is to plot and visualize the most wrong predictions of our fine-tuning model. We obtain our final dataframe using the following code block and sort the dataframe records in the descending order of the 'Prediction Probability':","metadata":{}},{"cell_type":"code","source":"Predictions = Predictions[Predictions[\"Correct Prediction\"] == False].sort_values(\"Prediction Probability\", ascending=False)\nPredictions","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:56:44.007943Z","iopub.execute_input":"2022-09-06T05:56:44.008582Z","iopub.status.idle":"2022-09-06T05:56:44.036386Z","shell.execute_reply.started":"2022-09-06T05:56:44.008543Z","shell.execute_reply":"2022-09-06T05:56:44.035319Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"indexes = np.asarray(Predictions[\"Image Index\"][:9]) #choosing the top 9 records from the dataframe\nplt.figure(figsize=(20,20))\nfor i, x in enumerate(indexes):\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_images[x]/255)\n    plt.title(\"True Class: \" + train_classes[test_labels[x]] + \" || \" + \"Predicted Class: \" + train_classes[pred_labels[x]] + \"\\n\" +\n             \"Prediction Probability: \" + str(np.asarray(tf.reduce_max(preds, axis = 1))[x]))\n    plt.axis(False);","metadata":{"execution":{"iopub.status.busy":"2022-09-06T05:56:46.631867Z","iopub.execute_input":"2022-09-06T05:56:46.632578Z","iopub.status.idle":"2022-09-06T05:56:48.479906Z","shell.execute_reply.started":"2022-09-06T05:56:46.632539Z","shell.execute_reply":"2022-09-06T05:56:48.478830Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Our final dataframe Predictions contains only the wrongly predicted image records (image indexes) along with their ground truth test labels, test classes, predicted labels, prediction classes sorted by the descending order of their prediction probabilities. We can manually take an image index out of this dataset and pass it into a plot function on the test dataset to obtain a visualization of the image with its ground truth class name and the predicted class name. However, here we will take the first 9 images or image indexes which are the most wrong images in our dataframe and plot it along with the true class names, the predicted class names and the corresponding prediction probabilities.","metadata":{}},{"cell_type":"markdown","source":"# Submission to Zindi plateforme\n","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/data-test/Test.csv')\ntest = test[~test.Image_id.str.contains('_rgn')] # Just the RGB images","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:00.705746Z","iopub.execute_input":"2022-09-06T06:00:00.706116Z","iopub.status.idle":"2022-09-06T06:00:00.736876Z","shell.execute_reply.started":"2022-09-06T06:00:00.706083Z","shell.execute_reply":"2022-09-06T06:00:00.735883Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"test_list = test['Image_id'].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:12.207933Z","iopub.execute_input":"2022-09-06T06:00:12.208352Z","iopub.status.idle":"2022-09-06T06:00:12.214956Z","shell.execute_reply.started":"2022-09-06T06:00:12.208316Z","shell.execute_reply":"2022-09-06T06:00:12.213207Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'Image_id': test['Image_id']})","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:22.355383Z","iopub.execute_input":"2022-09-06T06:00:22.355743Z","iopub.status.idle":"2022-09-06T06:00:22.361791Z","shell.execute_reply.started":"2022-09-06T06:00:22.355711Z","shell.execute_reply":"2022-09-06T06:00:22.360466Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"submission['blast'] = 0\nsubmission['brown'] = 0\nsubmission['healthy'] = 0","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:33.559746Z","iopub.execute_input":"2022-09-06T06:00:33.560154Z","iopub.status.idle":"2022-09-06T06:00:33.567689Z","shell.execute_reply.started":"2022-09-06T06:00:33.560118Z","shell.execute_reply":"2022-09-06T06:00:33.566595Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def convert_array(id_image): \n    path_image = '../input/test-images/Test_images/' + id_image\n    img = Image.open(path_image)\n    imgarray = np.asarray(img)\n    tensor_from_img = tf.convert_to_tensor(imgarray)\n    x = expand_dims(tensor_from_img, axis = 0)\n    predict = model.predict(x)\n    \n    return predict[0].tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:43.678515Z","iopub.execute_input":"2022-09-06T06:00:43.678863Z","iopub.status.idle":"2022-09-06T06:00:43.685327Z","shell.execute_reply.started":"2022-09-06T06:00:43.678831Z","shell.execute_reply":"2022-09-06T06:00:43.684255Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"for i, id_img in enumerate(test_list):\n    submission.iloc[i, 1:] = convert_array(id_img)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:00:55.103235Z","iopub.execute_input":"2022-09-06T06:00:55.103662Z","iopub.status.idle":"2022-09-06T06:02:01.764224Z","shell.execute_reply.started":"2022-09-06T06:00:55.103617Z","shell.execute_reply":"2022-09-06T06:02:01.763244Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:03:48.799453Z","iopub.execute_input":"2022-09-06T06:03:48.800081Z","iopub.status.idle":"2022-09-06T06:03:48.819207Z","shell.execute_reply.started":"2022-09-06T06:03:48.800024Z","shell.execute_reply":"2022-09-06T06:03:48.817711Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submissions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:03:52.203528Z","iopub.execute_input":"2022-09-06T06:03:52.203893Z","iopub.status.idle":"2022-09-06T06:03:52.222025Z","shell.execute_reply.started":"2022-09-06T06:03:52.203862Z","shell.execute_reply":"2022-09-06T06:03:52.221074Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"markdown","source":"We append the model to the list of models as a new version","metadata":{}},{"cell_type":"code","source":"! mkdir '../working/models'","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:03:54.804244Z","iopub.execute_input":"2022-09-06T06:03:54.804602Z","iopub.status.idle":"2022-09-06T06:03:55.976592Z","shell.execute_reply.started":"2022-09-06T06:03:54.804570Z","shell.execute_reply":"2022-09-06T06:03:55.975302Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"import os\nmodel_version = max([int(i) for i in os.listdir('../working/models')+[0]]) + 1","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:04:52.811332Z","iopub.execute_input":"2022-09-06T06:04:52.811892Z","iopub.status.idle":"2022-09-06T06:04:52.818535Z","shell.execute_reply.started":"2022-09-06T06:04:52.811851Z","shell.execute_reply":"2022-09-06T06:04:52.817405Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model.save(f'../working/models/{model_version}')","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:05:09.221724Z","iopub.execute_input":"2022-09-06T06:05:09.222097Z","iopub.status.idle":"2022-09-06T06:05:49.515877Z","shell.execute_reply.started":"2022-09-06T06:05:09.222062Z","shell.execute_reply":"2022-09-06T06:05:49.514867Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model.save(f\"../working/models/{model_version}/rice_disease.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:08:24.979793Z","iopub.execute_input":"2022-09-06T06:08:24.980737Z","iopub.status.idle":"2022-09-06T06:08:25.667545Z","shell.execute_reply.started":"2022-09-06T06:08:24.980692Z","shell.execute_reply":"2022-09-06T06:08:25.666535Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf Saved_model.tar.gz  ./models","metadata":{"execution":{"iopub.status.busy":"2022-09-06T06:08:30.247078Z","iopub.execute_input":"2022-09-06T06:08:30.248126Z","iopub.status.idle":"2022-09-06T06:08:36.604352Z","shell.execute_reply.started":"2022-09-06T06:08:30.248076Z","shell.execute_reply":"2022-09-06T06:08:36.603062Z"},"trusted":true},"execution_count":70,"outputs":[]}]}